
###### 【軟體工程師 - Network Infrastructure】

**工作內容**：

- Provide solutions of monitoring, logging, and alerting capabilities for next generation monitoring systems.
- Develop scalable and distributed network services.
- Develop services with vagrant and Docker containers.
- Work with front end engineers and devops engineers.
- Evaluate third party/ open source software.

**基本要求**：

- Knowledge of computer network and TCP/IP.
- Proficient in Golang, Python, Perl, or Ruby.
- Develop and augment RESTful APIs (web services) based on Node.js and golang.
- Experience with branch, write, test, commit and deploy code across servers.
- Familiar with SQL and databases like MySQL or PostgreSQL.
- Problem-solving skills with an emphasis on resolution of complex technical application and infrastructure
- Knowledge and experience with proper software development disciplines including: source code management, team development/collaboration and controlled releases.


**加分項目**：

- Experience with CDN technology. (Squid, Nginx, ...)
- Experience with cloud computing (e.g. distributed filesystem, BigTable and MapReduce framework.)
- Proficient understanding of System Engineering, including using isolated networks such as VPN, SSL, SSH and firewalls to fulfill any possible security considerations.
- Understanding and experience participating in mature software development testing methodologies including: test driven development, unit, functional and integration testing.
- Experience with Open Source web servers, message queueing and APIs.
- Proficient in developing system-engineering solutions to help with achieving highly available and scalable systems.
- Experience evaluating and leveraging 3rd party commercial and open source System Engineering/Dev Ops solutions.

###### 【軟體工程師 - Big Data】

**工作內容**：

- Analyze server usage data, and define correct metrics that help shape the product better.
- Diagnostics and troubleshooting of operational issues.
- Predict anomaly.

**基本要求**：

- Good programming skills in Python, R, Scala or Java.
- Experience with managing and processing Big Data (terabytes of data present in web logs).
- Experience with distributed programming platform such as Hadoop (YARN) or Spark.
- Proficient in data analysis and visualization using R or PyData.
- Familiar with SQL and databases like MySQL or PostgreSQL.
- Desire to explore lots of data to find unexpected insights.

**加分項目**：

- Experience working with very large datasets
- Real-time Hadoop query engines like Dremel, Cloudera Impala, Facebook Presto or Berkley Spark/Shark.
- Working knowledge of real time events processing frameworks like Storm, S4 or Spark Streaming
- Knowledge of main Hadoop ecosystem tools like Hive, Pig, Cascading, Sqoop, Flume, Hue, Oozie and etc.
- Experience with database handing time series data such as OpenTSDB, or InfluxDB.
- Experience with various Hadoop data store formats from CSV and JSON to ORC Files and Parquet.
- Knowledge of NoSQL engines like MongoDB, Cassandra, Couchbase, Redis and etc.
- Understanding of machine learning techniques and experience of using tools as R, Mahout, scikit-learn
- Experience with Amazon technologies like Elastic MapReduce, RedShift, DynamoDB.
- Working knowledge of ELS stack (Elasticsearch, Logstash, and Kibana).
